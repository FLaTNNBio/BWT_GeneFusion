# ğŸ“Œ Progetto: BWT_GeneFusion

## âš™ï¸ Requisiti

### ğŸ“Œ Versione Python
Il progetto Ã¨ stato sviluppato e testato con **Python 3.10+**.

### ğŸ“¦ Pacchetti richiesti
Per installare tutti i pacchetti necessari, eseguire:
```bash
pip install scikit-learn pandas numpy seaborn matplotlib biopython
```

- **scikit-learn** â†’ Per l'addestramento dei modelli di Machine Learning (SVM, Naive Bayes, Rete Neurale)
- **pandas** â†’ Per la gestione dei dataset CSV
- **numpy** â†’ Per operazioni matematiche avanzate
- **seaborn & matplotlib** â†’ Per la visualizzazione dei risultati (grafici e matrici di confusione)
- **biopython** â†’ Per la gestione dei file FASTA

---
### ğŸ“Œ File di partenza 
fusim_bench.fasta : contiene le sequenze che presentano gene fusion
all_transcripts.fasta : contiene le sequenze che non presentano gene fusion 
genes_panel.txt : elenco di geni delle sequenze
---

## ğŸ“‚ Workflow e Utilizzo degli Script

### 1ï¸âƒ£ **Applicazione della BWT alle sequenze**
**Script:** `bwt_input_fasta.py`

**Utilizzo:**
```bash
python bwt_input_fasta.py fusim_bench.fasta -o fusim_bench_bwt.csv
```
ğŸ“Œ **Output:**
- `fusim_bench_bwt.csv` â†’ Sequenze con gene fusion con BWT applicata

---

### 2ï¸âƒ£ **Divisione delle sequenze lunghe (senza gene fusion) in blocchi**
**Script:** `dividiInBlocchi.py`

**Utilizzo:**
```bash
python dividiInBlocchi.py all_transcripts.fasta -o all_transcripts_blocks.fasta
```
ğŸ“Œ **Output:**
- `all_transcripts_blocks.fasta` â†’ Sequenze lunghe divise in blocchi piÃ¹ corti per uniformarle a quelle con gene fusion
                                   il numero di blocchi scelto per ogni sequenza Ã¨ stato scelto per ottenere un numero simile agli elementi 
                                   di fusim_bench.fasta
---

### 3ï¸âƒ£ **Applicazione della BWT ai blocchi generati**
**Script:** `bwt_input_fasta.py`

**Utilizzo:**
```bash
python bwt_input_fasta.py all_transcripts_blocks.fasta -o all_transcripts_blocks_bwt.csv
```
ğŸ“Œ **Output:**
- `all_transcripts_blocks_bwt.csv` â†’ BWT applicata ai blocchi

ğŸ“Œ **Nota:** I due CSV (`fusim_bench_bwt.csv` e `all_transcripts_blocks_bwt.csv`) vengono poi uniti manualmente in un unico file full_dataset.csv.
    Nel file full_dataset.csv abbiamo anche una colonna "Label" che indica la tipologia di ogni sequenza (0 = no gene fusion, 1 = gene fusion)

---

### 4ï¸âƒ£ **Estrazione dei B-mers dalle sequenze BWT**
**Script:** `estrai_features.py`

**Utilizzo:**
```bash
python estrai_features.py full_dataset.csv -o full_dataset_bmers.csv --min_freq k (specifica valore k)
```
ğŸ“Œ **Output:**
- `full_dataset_bmers.csv` â†’ File con i B-mers estratti, che compaiono almeno **k volte** in una sequenza

---

### 5ï¸âƒ£ **Creazione dei vettori numerici per il Machine Learning**
**Script:** `crea_vettoriNumerici.py`

**Utilizzo:**
```bash
python crea_vettoriNumerici.py full_dataset_bmers.csv -o full_dataset_vectors.csv
```
ğŸ“Œ **Output:**
- `full_dataset_vectors.csv` â†’ Dataset che organizza le sequenze sulle righe ed i b-mers sulle colonne, 
                               ogni cella contiene il numero di volte che un bmer j-esimo compare in una sequenza i-esima

---

### 6ï¸âƒ£ **Arrotondamento dei valori con numeri periodici**
**Script:** `arrotondamento_periodici.py`

**Utilizzo:**
```bash
python arrotondamento_periodici.py full_dataset_vectors.csv -o full_dataset_vectors_rounded.csv
```
ğŸ“Œ **Output:**
- `full_dataset_vectors_rounded.csv` â†’ Dataset con valori arrotondati

---

### 7ï¸âƒ£ **Riduzione del dataset con ECCD (Entropy-based Category Coverage Difference)**
**Script:** `eccd.py`

**Utilizzo:**
```bash
python eccd.py full_dataset_vectors_rounded.csv -o full_dataset_vectors_reduced.csv
```
ğŸ“Œ **Output:**
- `full_dataset_vectors_reduced.csv` â†’ Dataset ridotto eliminando le feature meno informative

---

### 8ï¸âƒ£ **Addestramento dei modelli di Machine Learning**

#### ğŸ”¹ **Support Vector Machine (SVM)**
**Script:** `train_svm.py`

**Utilizzo:**
```bash
python train_svm.py full_dataset_vectors_reduced.csv
```
ğŸ“Œ **Output:**
- Stampa **accuracy**, **precision**, **recall** e **f1-score**
- Genera **matrice di confusione** come immagine PNG

#### ğŸ”¹ **Naive Bayes**
**Script:** `train_naiveBayes.py`

**Utilizzo:**
```bash
python train_naiveBayes.py full_dataset_vectors_reduced.csv
```
ğŸ“Œ **Output:**
- Stampa **accuracy**, **precision**, **recall** e **f1-score**
- Genera **matrice di confusione** come immagine PNG

#### ğŸ”¹ **Rete Neurale (MLPClassifier)**
**Script:** `train_reteNeurale.py`

**Utilizzo:**
```bash
python train_reteNeurale.py full_dataset_vectors_reduced.csv
```
ğŸ“Œ **Output:**
- Stampa **accuracy**, **precision**, **recall** e **f1-score**
- Genera **matrice di confusione** come immagine PNG


#### ğŸ”¹ **Random Forest**
**Script:** `train_randomForest.py`

**Utilizzo:**
```bash
python train_randomForest.py full_dataset_vectors_reduced.csv
```
ğŸ“Œ **Output:**
- Stampa **accuracy**, **precision**, **recall** e **f1-score**
- Genera **matrice di confusione** come immagine PNG



---

## ğŸ“Š Confronto dei Modelli
Dopo aver eseguito gli script di addestramento, Ã¨ possibile confrontare i risultati ottenuti dai diversi algoritmi


---

## ğŸ“Œ Conclusione
Questo progetto consente di estrarre dalla BWT delle sequenze a disposizione i b-mers che vengono usati come dati per l'addestramento e il test di diversi algoritmi di machine learning.
Le prestazioni, riguardanti la classificazione delle sequenze in due classi (0: no gene fusion, 1 gene fusion), degli algoritmi, vengono confrontate per visualizzare quale modello classifica con maggiore accuratezza.

ğŸ“© Contatti: v.tarantino7@studenti.unisa.it ,  bmazzeo3@studenti.unisa.it
